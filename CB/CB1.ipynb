{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ehallmar/beers-breweries-and-beer-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m28qsiLnEP0U",
        "outputId": "f63583ba-e720-4957-d56f-a456d9d24223"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'beers-breweries-and-beer-reviews' dataset.\n",
            "Path to dataset files: /kaggle/input/beers-breweries-and-beer-reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import KFold as SurpriseKFold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "WEANXRwvESNs",
        "outputId": "087caaea-3956-4e10-e08e-c397f3447b67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'surprise'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-919425243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSurpriseKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--전처리 내용--"
      ],
      "metadata": {
        "id": "KQ6qvNUIzyN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CB Model 정의"
      ],
      "metadata": {
        "id": "6rJB7HVEKxZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, List, Optional, Sequence, Tuple, Union\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from scipy import sparse as sp\n",
        "except ImportError:\n",
        "    sp = None\n",
        "\n",
        "def _is_sparse(X) -> bool:\n",
        "    return sp is not None and sp.issparse(X)\n",
        "\n",
        "def _l2_normalize_rows(X):\n",
        "    \"\"\"\n",
        "    Row-wise L2 normalization. Works for CSR (preferred) or dense ndarray.\n",
        "    Zero rows remain zero.\n",
        "    \"\"\"\n",
        "    if _is_sparse(X):\n",
        "        X = X.tocsr(copy=True)\n",
        "        row_norms = np.sqrt(X.multiply(X).sum(axis=1)).A1\n",
        "        nz = row_norms > 0\n",
        "        inv = np.zeros_like(row_norms)\n",
        "        inv[nz] = 1.0 / row_norms[nz]\n",
        "        D = sp.diags(inv)\n",
        "        return D @ X\n",
        "    else:\n",
        "        X = np.asarray(X, dtype=np.float32)\n",
        "        row_norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "        row_norms[row_norms == 0] = 1.0\n",
        "        return X / row_norms\n",
        "\n",
        "def _now_ts_from(interactions: pd.DataFrame, ts_col: str) -> pd.Timestamp:\n",
        "    \"\"\"Infer a 'now' timestamp from data (max ts).\"\"\"\n",
        "    ts = interactions[ts_col]\n",
        "    if np.issubdtype(ts.dtype, np.datetime64):\n",
        "        return ts.max()\n",
        "    try:\n",
        "        return pd.to_datetime(ts, unit=\"s\").max()\n",
        "    except Exception:\n",
        "        return pd.to_datetime(ts).max()\n",
        "\n",
        "def _to_datetime(series: pd.Series) -> pd.Series:\n",
        "    if np.issubdtype(series.dtype, np.datetime64):\n",
        "        return series\n",
        "    try:\n",
        "        return pd.to_datetime(series, unit=\"s\", errors=\"coerce\")\n",
        "    except Exception:\n",
        "        return pd.to_datetime(series, errors=\"coerce\")\n",
        "\n",
        "# ---------- 모델 ----------\n",
        "\n",
        "@dataclass\n",
        "class CBConfig:\n",
        "    rating_threshold: float = 4.0        # 좋아요(1)로 간주할 평점 임계\n",
        "    min_liked_items: int = 1            # 유저 프로파일 생성 최소 아이템 수\n",
        "    use_recency: bool = True            # 최근성 가중치 사용 여부\n",
        "    half_life_days: float = 60.0        # 최근성 half-life (일)\n",
        "    # base weight = max(score - rating_threshold + 0.5, 0.0)\n",
        "    # final weight = base * recency_decay\n",
        "\n",
        "class CBModel:\n",
        "    \"\"\"\n",
        "    콘텐츠 기반 추천 모델 (프로포절 규격: style OHE + abv 표준화 + 유저프로파일 + 코사인).\n",
        "    - fit_items: 전처리 산출 아이템 특징 행렬을 로드하고 L2 정규화\n",
        "    - build_user_profiles: (user,item,score,ts)로 유저 벡터 계산\n",
        "    - score_user_items: 특정 유저-후보 아이템 유사도 점수\n",
        "    - recommend: Top-N 추천\n",
        "    - predict_pairs: (user,item) 쌍의 cb_similarity_score 산출 (스태킹 입력)\n",
        "    \"\"\"\n",
        "    def __init__(self, config: Optional[CBConfig] = None):\n",
        "        self.cfg = config or CBConfig()\n",
        "        self.item_features = None\n",
        "        self.beer_id_to_idx: Dict[Union[int, str], int] = {}\n",
        "        self.idx_to_beer_id: np.ndarray = np.array([], dtype=object)\n",
        "        self.user_profiles: Dict[Union[int, str], np.ndarray] = {}\n",
        "        self.seen_items_by_user: Dict[Union[int, str], set] = {}\n",
        "\n",
        "    # ----- 아이템 영역 -----\n",
        "\n",
        "    def fit_items(self, X_items, beer_ids: Sequence[Union[int, str]]):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        X_items : csr_matrix or ndarray, shape (n_items, d)\n",
        "            아이템 특징 행렬 (style OHE, abv_scaled 등 포함).\n",
        "        beer_ids : array-like\n",
        "            각 행에 대응하는 beer_id.\n",
        "        \"\"\"\n",
        "        if _is_sparse(X_items):\n",
        "            X = X_items.tocsr()\n",
        "        else:\n",
        "            X = np.asarray(X_items, dtype=np.float32)\n",
        "        # Row-wise L2 normalize for cosine similarity via dot\n",
        "        self.item_features = _l2_normalize_rows(X)\n",
        "        self.idx_to_beer_id = np.asarray(beer_ids)\n",
        "        self.beer_id_to_idx = {bid: i for i, bid in enumerate(self.idx_to_beer_id)}\n",
        "        return self\n",
        "\n",
        "    # ----- 유저 프로파일 -----\n",
        "\n",
        "    def build_user_profiles(\n",
        "        self,\n",
        "        interactions: pd.DataFrame,\n",
        "        user_col: str = \"user_id\",\n",
        "        item_col: str = \"beer_id\",\n",
        "        rating_col: str = \"score\",\n",
        "        ts_col: Optional[str] = \"ts\",\n",
        "    ):\n",
        "        \"\"\"\n",
        "        유저별로 '좋아요'에 해당하는 아이템 벡터의 가중 평균으로 프로파일을 생성하고 L2 정규화.\n",
        "        - weight = max(score - threshold + 0.5, 0) * recency_decay\n",
        "        - recency_decay = 0.5 ** (delta_days / half_life)\n",
        "        \"\"\"\n",
        "        assert self.item_features is not None,\n",
        "\n",
        "        df = interactions[[user_col, item_col, rating_col] + ([ts_col] if ts_col else [])].copy()\n",
        "        # seen log (추천 제외 처리에 활용)\n",
        "        self.seen_items_by_user = (\n",
        "            df.groupby(user_col)[item_col].apply(lambda s: set(s.values)).to_dict()\n",
        "        )\n",
        "\n",
        "        # filtering by rating threshold\n",
        "        th = self.cfg.rating_threshold\n",
        "        liked = df[df[rating_col] >= th].copy()\n",
        "\n",
        "        # recency weights\n",
        "        if self.cfg.use_recency and ts_col and ts_col in liked.columns:\n",
        "            liked[ts_col] = _to_datetime(liked[ts_col])\n",
        "            now_ts = _now_ts_from(liked, ts_col)\n",
        "            delta_days = (now_ts - liked[ts_col]).dt.days.clip(lower=0).astype(float)\n",
        "            recency_decay = np.power(0.5, delta_days / max(self.cfg.half_life_days, 1e-6))\n",
        "        else:\n",
        "            recency_decay = np.ones(len(liked), dtype=np.float32)\n",
        "\n",
        "        base = (liked[rating_col] - th + 0.5).clip(lower=0).astype(float)\n",
        "        weights = (base * recency_decay).astype(np.float32).values\n",
        "\n",
        "        # accumulate weighted sum per user\n",
        "        # build mapping only for items existing in item_features\n",
        "        item_idx = liked[item_col].map(self.beer_id_to_idx).values\n",
        "        valid = ~pd.isna(item_idx)\n",
        "        liked = liked[valid]\n",
        "        weights = weights[valid]\n",
        "        item_idx = item_idx[valid].astype(int)\n",
        "\n",
        "        # group by user\n",
        "        users = liked[user_col].values\n",
        "        # prepare result dict\n",
        "        d = self.item_features.shape[1]\n",
        "        self.user_profiles = {}\n",
        "\n",
        "        # To speed up, process per user\n",
        "        # collect indices per user\n",
        "        by_user: Dict[Union[int, str], List[int]] = {}\n",
        "        by_weight: Dict[Union[int, str], List[float]] = {}\n",
        "        for u, i, w in zip(users, item_idx, weights):\n",
        "            by_user.setdefault(u, []).append(i)\n",
        "            by_weight.setdefault(u, []).append(w)\n",
        "\n",
        "        for u, idxs in by_user.items():\n",
        "            wts = np.asarray(by_weight[u], dtype=np.float32)\n",
        "            if len(idxs) < self.cfg.min_liked_items or wts.sum() <= 0:\n",
        "                continue\n",
        "            if _is_sparse(self.item_features):\n",
        "                # weighted sum of rows\n",
        "                row_stack = self.item_features[idxs]\n",
        "                prof = (row_stack.T @ sp.csr_matrix(wts).T).A1\n",
        "            else:\n",
        "                prof = (self.item_features[idxs] * wts[:, None]).sum(axis=0)\n",
        "            # L2 normalize\n",
        "            norm = np.linalg.norm(prof)\n",
        "            if norm == 0:\n",
        "                continue\n",
        "            self.user_profiles[u] = (prof / norm).astype(np.float32)\n",
        "\n",
        "        return self\n",
        "\n",
        "    # ----- 스코어링/추천 -----\n",
        "\n",
        "    def score_user_items(\n",
        "        self,\n",
        "        user_id: Union[int, str],\n",
        "        candidate_beer_ids: Optional[Sequence[Union[int, str]]] = None,\n",
        "        default_score: float = 0.0,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        scores : np.ndarray, shape (n_candidates,)\n",
        "            코사인 유사도 점수 벡터\n",
        "        cand_ids : np.ndarray\n",
        "            입력 후보 beer_id 배열(매핑 실패 제외)\n",
        "        \"\"\"\n",
        "        if self.item_features is None:\n",
        "            raise RuntimeError(\"fit_items 먼저 호출하세요.\")\n",
        "        user_vec = self.user_profiles.get(user_id, None)\n",
        "        if user_vec is None:\n",
        "            # cold-start user → 점수 0 (또는 인기기반 후처리에서 대체)\n",
        "            if candidate_beer_ids is None:\n",
        "                cand_ids = self.idx_to_beer_id\n",
        "                scores = np.full(len(cand_ids), default_score, dtype=np.float32)\n",
        "            else:\n",
        "                cand_ids = np.asarray(candidate_beer_ids)\n",
        "                scores = np.full(len(cand_ids), default_score, dtype=np.float32)\n",
        "            return scores, np.asarray(cand_ids)\n",
        "\n",
        "        if candidate_beer_ids is None:\n",
        "            cand_idx = np.arange(self.item_features.shape[0], dtype=int)\n",
        "            cand_ids = self.idx_to_beer_id\n",
        "        else:\n",
        "            # map to indices, drop unknowns\n",
        "            cand_ids = np.asarray(candidate_beer_ids)\n",
        "            cand_idx = np.array(\n",
        "                [self.beer_id_to_idx.get(b, -1) for b in cand_ids], dtype=int\n",
        "            )\n",
        "            mask = cand_idx >= 0\n",
        "            cand_idx = cand_idx[mask]\n",
        "            cand_ids = cand_ids[mask]\n",
        "\n",
        "        # cosine via dot since rows L2-normalized\n",
        "        if _is_sparse(self.item_features):\n",
        "            scores = self.item_features[cand_idx].dot(user_vec).astype(np.float32)\n",
        "            scores = np.asarray(scores).ravel()\n",
        "        else:\n",
        "            scores = (self.item_features[cand_idx] @ user_vec).astype(np.float32)\n",
        "\n",
        "        return scores, cand_ids\n",
        "\n",
        "    def recommend(\n",
        "        self,\n",
        "        user_id: Union[int, str],\n",
        "        k: int = 10,\n",
        "        candidate_beer_ids: Optional[Sequence[Union[int, str]]] = None,\n",
        "        exclude_seen: bool = True,\n",
        "    ) -> List[Tuple[Union[int, str], float]]:\n",
        "        \"\"\"\n",
        "        Top-N 추천 반환: [(beer_id, score), ...]\n",
        "        \"\"\"\n",
        "        scores, cand_ids = self.score_user_items(user_id, candidate_beer_ids)\n",
        "        # exclude seen\n",
        "        if exclude_seen:\n",
        "            seen = self.seen_items_by_user.get(user_id, set())\n",
        "            mask = np.array([bid not in seen for bid in cand_ids], dtype=bool)\n",
        "            cand_ids = cand_ids[mask]\n",
        "            scores = scores[mask]\n",
        "        if len(scores) == 0:\n",
        "            return []\n",
        "        topk = np.argpartition(-scores, kth=min(k, len(scores)-1))[:k]\n",
        "        order = topk[np.argsort(-scores[topk])]\n",
        "        return [(cand_ids[i].item() if hasattr(cand_ids[i], \"item\") else cand_ids[i],\n",
        "                 float(scores[i]))\n",
        "                for i in order]\n",
        "\n",
        "    def predict_pairs(\n",
        "        self,\n",
        "        pairs: pd.DataFrame,\n",
        "        user_col: str = \"user_id\",\n",
        "        item_col: str = \"beer_id\",\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        스태킹 Level-0 특징으로 쓸 (user,item)별 cb_similarity_score 생성.\n",
        "        \"\"\"\n",
        "        assert self.item_features is not None,\n",
        "        out = np.zeros(len(pairs), dtype=np.float32)\n",
        "        # group by user for vectorized scoring\n",
        "        for u, grp in pairs.groupby(pairs[user_col].values):\n",
        "            scores, cand_ids = self.score_user_items(u, grp[item_col].values)\n",
        "            # align scores to grp order (cand_ids is a subset; we kept order)\n",
        "            out[grp.index] = scores\n",
        "        return out\n",
        "\n",
        "# ---------- 스태킹 OOF 유틸 ----------\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def make_cb_oof_scores(\n",
        "    interactions: pd.DataFrame,\n",
        "    X_items,\n",
        "    beer_ids: Sequence[Union[int, str]],\n",
        "    n_splits: int = 5,\n",
        "    random_state: int = 42,\n",
        "    user_col: str = \"user_id\",\n",
        "    item_col: str = \"beer_id\",\n",
        "    rating_col: str = \"score\",\n",
        "    ts_col: Optional[str] = \"ts\",\n",
        "    cfg: Optional[CBConfig] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    상호작용 단위 KFold로 OOF cb_similarity_score 생성.\n",
        "    - fold마다: CBModel(아이템 고정) + 유저프로파일은 '학습 폴드' 상호작용으로만 생성\n",
        "    - 검증 폴드 (user,item) 쌍에 대해 점수를 예측\n",
        "    Returns: DataFrame[pairs + cb_similarity_score]\n",
        "    \"\"\"\n",
        "    pairs_cols = [user_col, item_col]\n",
        "    df = interactions[[user_col, item_col, rating_col] + ([ts_col] if ts_col else [])].copy()\n",
        "    df = df.reset_index(drop=True)\n",
        "    oof = np.zeros(len(df), dtype=np.float32)\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(df), start=1):\n",
        "        tr = df.iloc[tr_idx]\n",
        "        va = df.iloc[va_idx]\n",
        "        cb = CBModel(cfg)\n",
        "        cb.fit_items(X_items, beer_ids)\n",
        "        cb.build_user_profiles(tr, user_col=user_col, item_col=item_col,\n",
        "                               rating_col=rating_col, ts_col=ts_col)\n",
        "        oof[va_idx] = cb.predict_pairs(va[pairs_cols].copy(), user_col=user_col, item_col=item_col)\n",
        "        print(f\"[CB OOF] fold {fold}/{n_splits} done\")\n",
        "\n",
        "    out = df[pairs_cols].copy()\n",
        "    out[\"cb_similarity_score\"] = oof\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "0LJMAC-fCe0r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단순 검증용 테스트 코드"
      ],
      "metadata": {
        "id": "BO7fkmI8sgA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === POSITION-ONLY, ULTRA-LOW-RAM CB (no merge, no big copies) ===\n",
        "import numpy as np, pandas as pd, heapq, gc\n",
        "\n",
        "cf = df_for_cf\n",
        "meta = X_meta_base\n",
        "\n",
        "cf_ = cf.rename(columns={\"user\":\"user_id\",\"item\":\"beer_id\",\"rating\":\"score\"})[[\"user_id\",\"beer_id\",\"score\"]]\n",
        "\n",
        "# 피처 컬럼(순수 CB)\n",
        "style_cols = [c for c in meta.columns if str(c).startswith(\"style_\")]\n",
        "feat_cols = ([\"abv\"] if \"abv\" in meta.columns else []) + style_cols\n",
        "assert len(feat_cols) >= 2, \"X_meta_base에서 abv + style_*를 찾지 못함\"\n",
        "\n",
        "# 1) 타깃 유저 선택(좋아요 많은 유저)\n",
        "likes = cf_[cf_[\"score\"] >= 4.0]\n",
        "assert not likes.empty, \"평점≥4.0 데이터가 없음\"\n",
        "target_user = likes[\"user_id\"].value_counts().idxmax()\n",
        "print(\"[TARGET USER]\", target_user)\n",
        "\n",
        "# 유저 벡터: '좋아요 행'의 '행 인덱스'로 피처를 뽑아 가중합\n",
        "like_pos = likes.index[likes[\"user_id\"] == target_user].to_numpy()\n",
        "first_pos = pd.Series(like_pos).groupby(cf_.iloc[like_pos][\"beer_id\"].to_numpy()).first().to_numpy()\n",
        "\n",
        "X_like = meta.iloc[first_pos][feat_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
        "# 행 L2 정규화\n",
        "nrm = np.linalg.norm(X_like, axis=1, keepdims=True); nrm[nrm==0]=1.0\n",
        "X_like /= nrm\n",
        "\n",
        "w = (cf_.iloc[first_pos][\"score\"].to_numpy(dtype=np.float32) - 3.5).clip(min=0)\n",
        "U = (X_like * w[:, None]).sum(axis=0)\n",
        "u_norm = np.linalg.norm(U)\n",
        "if u_norm == 0:\n",
        "    raise RuntimeError(\"유저 벡터가 0입니다. 좋아요가 너무 적거나 전부 결측\")\n",
        "U = (U / u_norm).astype(np.float32)\n",
        "print(\"[USER VEC] ready; liked_rows:\", len(first_pos))\n",
        "\n",
        "K = 20\n",
        "CHUNK = 20_000\n",
        "top = []                   # (score, beer_id)\n",
        "processed = set()\n",
        "seen = set(cf_.loc[cf_[\"user_id\"] == target_user, \"beer_id\"].to_numpy())\n",
        "\n",
        "n = len(cf_)\n",
        "for s in range(0, n, CHUNK):\n",
        "    e = min(n, s+CHUNK)\n",
        "    ids = cf_.iloc[s:e][\"beer_id\"].to_numpy()\n",
        "    X = meta.iloc[s:e][feat_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
        "    # 행 L2 정규화\n",
        "    nrm = np.linalg.norm(X, axis=1, keepdims=True); nrm[nrm==0]=1.0\n",
        "    X /= nrm\n",
        "    # 유사도\n",
        "    scores = X @ U\n",
        "\n",
        "    for bid, sc in zip(ids, scores):\n",
        "        if bid in processed or bid in seen:\n",
        "            continue\n",
        "        processed.add(bid)\n",
        "        sc = float(sc)\n",
        "        if len(top) < K:\n",
        "            heapq.heappush(top, (sc, bid))\n",
        "        else:\n",
        "            if sc > top[0][0]:\n",
        "                heapq.heapreplace(top, (sc, bid))\n",
        "\n",
        "    del ids, X, scores\n",
        "    if (s // CHUNK) % 50 == 0: gc.collect()\n",
        "\n",
        "# 결과\n",
        "top_sorted = sorted(top, key=lambda x: -x[0])\n",
        "print(f\"\\n[TOP-{K} for user {target_user}]\")\n",
        "for sc, bid in top_sorted:\n",
        "    print(bid, round(sc, 4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZzD3bLKV8kL",
        "outputId": "ee9f6e75-cdbf-4613-ace2-0747011a5ec7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TARGET USER] kjkinsey\n",
            "[USER VEC] ready; liked_rows: 6291\n",
            "\n",
            "[TOP-20 for user kjkinsey]\n",
            "366894 0.9995\n",
            "57015 0.9995\n",
            "187253 0.9995\n",
            "311921 0.9995\n",
            "70633 0.9995\n",
            "368014 0.9994\n",
            "368012 0.9994\n",
            "365307 0.9994\n",
            "96666 0.9994\n",
            "104620 0.9994\n",
            "89801 0.9994\n",
            "83277 0.9994\n",
            "340204 0.9993\n",
            "73368 0.9993\n",
            "133448 0.9993\n",
            "356998 0.9993\n",
            "196590 0.9993\n",
            "176438 0.9993\n",
            "83276 0.9992\n",
            "57856 0.9992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CB-preproccesing"
      ],
      "metadata": {
        "id": "NFQaaGIguovb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- per-beer feature matrix (stable memory, no groupby merges) ---\n",
        "import numpy as np, pandas as pd, gc\n",
        "\n",
        "cf   = df_for_cf.rename(columns={\"user\":\"user_id\",\"item\":\"beer_id\",\"rating\":\"score\"})[[\"user_id\",\"beer_id\",\"score\"]]\n",
        "meta = X_meta_base\n",
        "\n",
        "# 피처 컬럼 정의\n",
        "style_cols = [c for c in meta.columns if str(c).startswith(\"style_\")]\n",
        "feat_cols  = ([\"abv\"] if \"abv\" in meta.columns else []) + style_cols\n",
        "d = len(feat_cols)\n",
        "assert d >= 2, \"X_meta_base에서 abv + style_*를 찾지 못했습니다.\"\n",
        "\n",
        "# 유니크 beer_id와 인덱스 매핑\n",
        "beer_ids = cf[\"beer_id\"].unique()\n",
        "n_beers  = beer_ids.shape[0]\n",
        "id2idx   = {bid: i for i, bid in enumerate(beer_ids)}\n",
        "\n",
        "# 누적 버퍼 준비 (고정 크기)\n",
        "sum_mat = np.zeros((n_beers, d), dtype=np.float32)\n",
        "cnt     = np.zeros(n_beers, dtype=np.int32)\n",
        "\n",
        "CHUNK = 50_000\n",
        "n = len(cf)\n",
        "for s in range(0, n, CHUNK):\n",
        "    e = min(n, s+CHUNK)\n",
        "\n",
        "    ids = cf.iloc[s:e][\"beer_id\"].to_numpy()\n",
        "    idx = np.fromiter((id2idx.get(b, -1) for b in ids), dtype=np.int64, count=ids.size)\n",
        "    keep = idx >= 0\n",
        "    if not np.any(keep):\n",
        "        continue\n",
        "    idx = idx[keep]\n",
        "\n",
        "    X = meta.iloc[s:e][feat_cols].to_numpy(copy=False)\n",
        "    X = pd.DataFrame(X, columns=feat_cols)\n",
        "    for c in feat_cols:\n",
        "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0).astype(np.float32)\n",
        "    X = X.to_numpy(dtype=np.float32, copy=False)\n",
        "    X = X[keep]\n",
        "\n",
        "    # 행 L2 정규화\n",
        "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1.0\n",
        "    X /= norms\n",
        "\n",
        "    np.add.at(sum_mat, idx, X)\n",
        "    np.add.at(cnt, idx, 1)\n",
        "\n",
        "    del ids, idx, keep, X, norms\n",
        "    if (s // CHUNK) % 10 == 0:\n",
        "        gc.collect()\n",
        "\n",
        "# 평균 → 행 L2 정규화\n",
        "cnt = np.maximum(cnt, 1).astype(np.float32)\n",
        "beer_avg = (sum_mat / cnt[:, None]).astype(np.float32)\n",
        "norms = np.linalg.norm(beer_avg, axis=1, keepdims=True)\n",
        "norms[norms == 0] = 1.0\n",
        "beer_mat = (beer_avg / norms).astype(np.float32)\n",
        "\n",
        "np.save(\"/content/beer_mat.npy\", beer_mat)         # (n_beers, d), row-normalized\n",
        "np.save(\"/content/beer_ids.npy\", beer_ids)         # beer_mat 행과 매칭되는 beer_id 배열\n",
        "print(\"SAVED:\", beer_mat.shape, \"→ /content/beer_mat.npy & /content/beer_ids.npy\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIfIf7UrZeD4",
        "outputId": "996e9c02-26fc-444d-9a01-0a9ae0bd4f1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAVED: (358873, 114) → /content/beer_mat.npy & /content/beer_ids.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/beer_mat.npy\")\n",
        "files.download(\"/content/beer_ids.npy\")\n",
        "files.download(\"/content/cb_topk.parquet\")"
      ],
      "metadata": {
        "id": "zeKSGruWs9dv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
